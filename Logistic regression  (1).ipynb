{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "492a0f01-6591-4769-af43-e3229d5340c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import csr_matrix\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dedafae-ec06-4178-9a9a-d3a66b1d1a8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39885</th>\n",
       "      <td>one of eastwood's best movies after he had sep...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17566</th>\n",
       "      <td>my blurred childhood memories have kept the ec...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16062</th>\n",
       "      <td>i love zombie-movies and i love amateur-produc...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48445</th>\n",
       "      <td>chan is in new york and he gets involved with ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20382</th>\n",
       "      <td>my wife and i both thought this film a watered...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "39885  one of eastwood's best movies after he had sep...  positive\n",
       "17566  my blurred childhood memories have kept the ec...  negative\n",
       "16062  i love zombie-movies and i love amateur-produc...  negative\n",
       "48445  chan is in new york and he gets involved with ...  positive\n",
       "20382  my wife and i both thought this film a watered...  negative"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('IMDB Dataset.csv')\n",
    "data['review'] = data['review'].str.lower()\n",
    "df = data.sample(frac = 0.10, random_state=42)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c4d46ad-8b9d-4fef-9434-8be5d4d674ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_81/2103317337.py:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['clean_review'] = df['clean_review'].str.replace('[{}]'.format(string.punctuation), ' ')\n"
     ]
    }
   ],
   "source": [
    "def remove_tags(string):\n",
    "    result = re.sub('<.*?>','',string)\n",
    "    return result\n",
    "    \n",
    "#data_without_stopwords = remove_stopwords(df)\n",
    "df['clean_review']= df['review'].apply(lambda cw : remove_tags(cw))\n",
    "df['clean_review'] = df['clean_review'].str.replace('[{}]'.format(string.punctuation), ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "813cfb95-39a9-4e59-9153-5c1f9d977cc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>clean_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39885</th>\n",
       "      <td>one of eastwood's best movies after he had sep...</td>\n",
       "      <td>positive</td>\n",
       "      <td>one of eastwood s best movies after he had sep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17566</th>\n",
       "      <td>my blurred childhood memories have kept the ec...</td>\n",
       "      <td>negative</td>\n",
       "      <td>my blurred childhood memories have kept the ec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16062</th>\n",
       "      <td>i love zombie-movies and i love amateur-produc...</td>\n",
       "      <td>negative</td>\n",
       "      <td>i love zombie movies and i love amateur produc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48445</th>\n",
       "      <td>chan is in new york and he gets involved with ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>chan is in new york and he gets involved with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20382</th>\n",
       "      <td>my wife and i both thought this film a watered...</td>\n",
       "      <td>negative</td>\n",
       "      <td>my wife and i both thought this film a watered...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment  \\\n",
       "39885  one of eastwood's best movies after he had sep...  positive   \n",
       "17566  my blurred childhood memories have kept the ec...  negative   \n",
       "16062  i love zombie-movies and i love amateur-produc...  negative   \n",
       "48445  chan is in new york and he gets involved with ...  positive   \n",
       "20382  my wife and i both thought this film a watered...  negative   \n",
       "\n",
       "                                            clean_review  \n",
       "39885  one of eastwood s best movies after he had sep...  \n",
       "17566  my blurred childhood memories have kept the ec...  \n",
       "16062  i love zombie movies and i love amateur produc...  \n",
       "48445  chan is in new york and he gets involved with ...  \n",
       "20382  my wife and i both thought this film a watered...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb5bb1b2-8d4a-4967-a180-9790b8704a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test,Y_train, Y_test = train_test_split(df['clean_review'], df['sentiment'], test_size=0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20a89345-9766-48c8-9d2a-5009585465ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_table = {ord(c): None for c in string.punctuation + string.digits}\n",
    "stemmer = PorterStemmer()\n",
    "def tokenize(text):\n",
    "        # my text was unicode so I had to use the unicode-specific translate function. If your documents are strings, you will need to use a different `translate` function here. `Translated` here just does search-replace. See the trans_table: any matching character in the set is replaced with `None`\n",
    "        tokens = [word for word in nltk.word_tokenize(text.translate(trans_table)) if len(word) > 1] #if len(word) > 1 because I only want to retain words that are at least two characters before stemming, although I can't think of any such words that are not also stopwords\n",
    "        stems = [stemmer.stem(item) for item in tokens]\n",
    "        return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "313fc690-c83c-431a-8f25-83444c815842",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df = 5,\n",
    "                             max_df = 0.8,\n",
    "                             sublinear_tf = True,\n",
    "                             use_idf = True,stop_words = 'english',lowercase = True,strip_accents ='unicode',tokenizer = tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e96880bb-23f2-499d-8a32-66cf36c145e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_vectors = vectorizer.fit_transform(X_train)\n",
    "test_vectors = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed5ac9bd-4e51-4109-9ec9-fa664d1f2ce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegr = LogisticRegression()\n",
    "logisticRegr.fit(train_vectors, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84ce176c-ac74-4aa0-8f1b-fcf6a32225a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_train = logisticRegr.predict(train_vectors)\n",
    "predict_test = logisticRegr.predict(test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f81b9308-3aab-4430-b1de-4743b9261776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9425714285714286\n",
      "0.846\n"
     ]
    }
   ],
   "source": [
    "score_train = logisticRegr.score(train_vectors,Y_train)\n",
    "score_test = logisticRegr.score(test_vectors, Y_test)\n",
    "print(score_train)\n",
    "print(score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ca9c63-9bed-4e29-ab54-da91ced3c998",
   "metadata": {},
   "source": [
    "# This is in a different way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32ae0118-97dd-4b89-bd33-c496506cd624",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import csr_matrix\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c3aad0d-6573-4f86-a339-7b14a02c090a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33553</th>\n",
       "      <td>i really liked this summerslam due to the look...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9427</th>\n",
       "      <td>not many television shows appeal to quite as m...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>the film quickly gets to a major chase scene w...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12447</th>\n",
       "      <td>jane austen would definitely approve of this o...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39489</th>\n",
       "      <td>expectations were somewhat high for me when i ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "33553  i really liked this summerslam due to the look...  positive\n",
       "9427   not many television shows appeal to quite as m...  positive\n",
       "199    the film quickly gets to a major chase scene w...  negative\n",
       "12447  jane austen would definitely approve of this o...  positive\n",
       "39489  expectations were somewhat high for me when i ...  negative"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('IMDB Dataset.csv')\n",
    "data['review'] = data['review'].str.lower()\n",
    "df = data.sample(frac = 0.10, random_state=42)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef39f05f-8b9a-459a-96e0-520a3e2b7400",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "194f19f9-99da-485a-90af-6d151040a49e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_81/4214519570.py:10: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data_without_stopwords['clean_review'] = data_without_stopwords['clean_review'].str.replace('[{}]'.format(string.punctuation), ' ')\n"
     ]
    }
   ],
   "source": [
    "def remove_stopwords(df):\n",
    "  df['review without stopwords'] = df['review'].apply(lambda x : ' '.join([word for word in x.split() if word not in (stopwords)]))\n",
    "  return df\n",
    "def remove_tags(string):\n",
    "    result = re.sub('<.*?>','',string)\n",
    "    return result\n",
    "    \n",
    "data_without_stopwords = remove_stopwords(df)\n",
    "data_without_stopwords['clean_review']= data_without_stopwords['review'].apply(lambda cw : remove_tags(cw))\n",
    "data_without_stopwords['clean_review'] = data_without_stopwords['clean_review'].str.replace('[{}]'.format(string.punctuation), ' ')\n",
    "df = data_without_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df9913c8-505f-4fa9-a495-6d4247101154",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df = 5,\n",
    "                             max_df = 0.8,\n",
    "                             sublinear_tf = True,\n",
    "                             use_idf = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f7585b4-2eb8-4067-b411-2cd52c6b0ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test,Y_train, Y_test = train_test_split(df['clean_review'], df['sentiment'], test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b53ef6b-8cd2-470a-963b-9cb7f90c2b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = vectorizer.fit_transform(X_train)\n",
    "test_vectors = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a8312e1-208f-4798-a2ee-8ff99dcfcbbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegr = LogisticRegression()\n",
    "logisticRegr.fit(train_vectors, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54d0c465-b544-485e-b7d7-728393d7df4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_train = logisticRegr.predict(train_vectors)\n",
    "predict_test = logisticRegr.predict(test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c5df039-077c-4dc9-9ca7-15724d204c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.94975\n",
      "0.856\n"
     ]
    }
   ],
   "source": [
    "score_train = logisticRegr.score(train_vectors,Y_train)\n",
    "score_test = logisticRegr.score(test_vectors, Y_test)\n",
    "print(score_train)\n",
    "print(score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9aa15b-8edf-45dd-a6fc-d8d65f54bdd0",
   "metadata": {},
   "source": [
    "# Another Way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f09f3f1-426d-4305-a9a7-e7efd760923b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6dee700a-c044-46d6-a0b2-20668a18e7df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33553</th>\n",
       "      <td>i really liked this summerslam due to the look...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9427</th>\n",
       "      <td>not many television shows appeal to quite as m...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>the film quickly gets to a major chase scene w...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12447</th>\n",
       "      <td>jane austen would definitely approve of this o...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39489</th>\n",
       "      <td>expectations were somewhat high for me when i ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "33553  i really liked this summerslam due to the look...  positive\n",
       "9427   not many television shows appeal to quite as m...  positive\n",
       "199    the film quickly gets to a major chase scene w...  negative\n",
       "12447  jane austen would definitely approve of this o...  positive\n",
       "39489  expectations were somewhat high for me when i ...  negative"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('IMDB Dataset.csv')\n",
    "data['review'] = data['review'].str.lower()\n",
    "df = data.sample(frac = 0.10, random_state=42)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d1be77d-72be-4ebf-b9c0-01746574e946",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_81/3132649063.py:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['clean_review'] = df['clean_review'].str.replace('[{}]'.format(string.punctuation), ' ')\n"
     ]
    }
   ],
   "source": [
    "def remove_tags(string):\n",
    "    result = re.sub('<.*?>','',string)\n",
    "    return result\n",
    "df['clean_review']= df['review'].apply(lambda cw : remove_tags(cw))\n",
    "df['clean_review'] = df['clean_review'].str.replace('[{}]'.format(string.punctuation), ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "efb602fb-a603-4cc0-a3fc-fb92c71708ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test,Y_train, Y_test = train_test_split(df['clean_review'], df['sentiment'], test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18de0c06-ecc8-4a97-9909-646c132ce3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer(stop_words='english')\n",
    "X_train = vec.fit_transform(X_train).toarray()\n",
    "X_test = vec.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84117ac4-1225-4d13-9fe8-b9d635c29464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegr = LogisticRegression()\n",
    "logisticRegr.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5066838d-8301-402a-a548-6775bf9abd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_train = logisticRegr.predict(X_train)\n",
    "predict_test = logisticRegr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1bacf462-ad9f-454a-bb0f-ae891e4698de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9995\n",
      "0.841\n"
     ]
    }
   ],
   "source": [
    "score_train = logisticRegr.score(X_train,Y_train)\n",
    "score_test = logisticRegr.score(X_test, Y_test)\n",
    "print(score_train)\n",
    "print(score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c3600c-84a5-4c00-9d65-797eab7bd5e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5804d898-c6a5-4b08-8737-1069c6b34ba1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064ee901-145f-46ef-83db-109156bdd0ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
