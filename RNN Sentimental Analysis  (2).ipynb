{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "MhsYAA5-RQGB"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.layers import LSTM, Activation, Dropout, Dense, Input\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.models import Model\n",
    "import string\n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python.keras.optimizer_v2.adam import Adam\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "bWTZEEMcRVrB",
    "outputId": "fc538858-cdb7-4275-c59e-7c1e4412cebe"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>i thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>i am a catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>i'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>no one expects the star trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "49995  i thought this movie did a down right good job...  positive\n",
       "49996  bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  i am a catholic taught in parochial elementary...  negative\n",
       "49998  i'm going to have to disagree with the previou...  negative\n",
       "49999  no one expects the star trek movies to be high...  negative"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('IMDB Dataset.csv')\n",
    "data['review'] = data['review'].str.lower()\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review       a wonderful little production. <br /><br />the...\n",
       "sentiment                                             positive\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CxHPAiLViyYK",
    "outputId": "1a217d7b-3391-42c6-b096-2b0cb6d486b3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "YfAS6s4RRcoE"
   },
   "outputs": [],
   "source": [
    "stopwords = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \n",
    "             \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\",\n",
    "             \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \n",
    "             \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\",\n",
    "             \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\",\n",
    "             \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \n",
    "             \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\",\n",
    "             \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\",\n",
    "             \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\",\n",
    "             \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\",\n",
    "             \"your\", \"yours\", \"yourself\", \"yourselves\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Ax2qIZoSSD8e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_49/2493842820.py:11: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data_without_stopwords['clean_review'] = data_without_stopwords['clean_review'].str.replace('[{}]'.format(string.punctuation), ' ')\n"
     ]
    }
   ],
   "source": [
    "def remove_stopwords(data):\n",
    "  data['review without stopwords'] = data['review'].apply(lambda x : ' '.join([word for word in x.split() if word not in (stopwords)]))\n",
    "  return data\n",
    "\n",
    "def remove_tags(string):\n",
    "    result = re.sub('<.*?>','',string)\n",
    "    return result\n",
    "    \n",
    "data_without_stopwords = remove_stopwords(data)\n",
    "data_without_stopwords['clean_review']= data_without_stopwords['review without stopwords'].apply(lambda cw : remove_tags(cw))\n",
    "data_without_stopwords['clean_review'] = data_without_stopwords['clean_review'].str.replace('[{}]'.format(string.punctuation), ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "dic-fvDiSIzh"
   },
   "outputs": [],
   "source": [
    "reviews_list = []\n",
    "for i in range(len(data.review)): \n",
    "  reviews_list.append(data.review[i])\n",
    "  sentiment = data_without_stopwords['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "jCXmHHfNSJre"
   },
   "outputs": [],
   "source": [
    "y = np.array(list(map(lambda x: 1 if x==\"positive\" else 0, sentiment)))\n",
    "\n",
    "X_train, X_test,Y_train, Y_test = train_test_split(reviews_list, y, test_size=0.2, random_state = 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v6tOfc_ee_pl",
    "outputId": "c228d3ea-2dab-4904-ebe7-1ec077cc6d3d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "fM4sO3VJTA7l"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "words_to_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "1OixbE0STE4N"
   },
   "outputs": [],
   "source": [
    "def read_glove_vector(glove_vec):\n",
    "  with open(glove_vec, 'r', encoding='UTF-8') as f:\n",
    "    words = set()\n",
    "    word_to_vec_map = {}\n",
    "    for line in f:\n",
    "      w_line = line.split()\n",
    "      curr_word = w_line[0]\n",
    "      word_to_vec_map[curr_word] = np.array(w_line[1:], dtype=np.float64)\n",
    "\n",
    "\n",
    "\n",
    "  return word_to_vec_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "AVF_JScGTHvL"
   },
   "outputs": [],
   "source": [
    "word_to_vec_map = read_glove_vector('glove.6B.50d.txt')\n",
    "\n",
    "maxLen = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ZADy1CISTIqT"
   },
   "outputs": [],
   "source": [
    "vocab_len = len(words_to_index)\n",
    "embed_vector_len = word_to_vec_map['moon'].shape[0]\n",
    "\n",
    "emb_matrix = np.zeros((vocab_len, embed_vector_len))\n",
    "\n",
    "for word, index in words_to_index.items():\n",
    "  embedding_vector = word_to_vec_map.get(word)\n",
    "  if embedding_vector is not None:\n",
    "    emb_matrix[index, :] = embedding_vector\n",
    "\n",
    "embedding_layer = Embedding(input_dim=vocab_len, output_dim=embed_vector_len, input_length=maxLen, weights = [emb_matrix], trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "-B9ReE4rTLbc"
   },
   "outputs": [],
   "source": [
    "def imdb_rating(input_shape):\n",
    "\n",
    "  X_indices = Input(input_shape)\n",
    "  print(X_indices)\n",
    "\n",
    "  embeddings = embedding_layer(X_indices)\n",
    "\n",
    "  X = LSTM(128, return_sequences=True)(embeddings) # First Layer\n",
    "\n",
    "  X = Dropout(0.15)(X)\n",
    "\n",
    "  X = LSTM(128, return_sequences=True)(X) # Second Layer\n",
    "\n",
    "  X = Dropout(0.15)(X)\n",
    "\n",
    "  X = LSTM(128)(X) # Third layer\n",
    "\n",
    "  X = Dense(1, activation='sigmoid')(X)\n",
    "\n",
    "  return  Model(inputs=X_indices, outputs=X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xQtfBjzRhUL9",
    "outputId": "cbe0359c-7613-4217-e79d-e9211c273634"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 150), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x7f13ec0dff70>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m= imdb_rating(150)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "1W_vROE6TPa3"
   },
   "outputs": [],
   "source": [
    "X_train_indices = tokenizer.texts_to_sequences(X_train)\n",
    "X_train_indices = pad_sequences(X_train_indices, maxlen=maxLen, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5h-6GuNxeVJO",
    "outputId": "cb81c6eb-92f2-4ba7-adb6-1d3e4f31142a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 167, 1910,    3, ...,    3,  955,   97],\n",
       "       [3633,    7,    7, ...,  608,  618,    1],\n",
       "       [  34,  905,    9, ...,  488,  488,   19],\n",
       "       ...,\n",
       "       [   6,  993,   14, ...,  542, 2438, 3380],\n",
       "       [  10,   37, 1240, ...,    0,    0,    0],\n",
       "       [  77,  206,  135, ...,   51, 3362, 1471]], dtype=int32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7hqD7wPwTTz8",
    "outputId": "2d56ddef-42be-4fba-b34a-14873a2d306e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/21\n",
      "625/625 [==============================] - 21s 26ms/step - loss: 0.5880 - accuracy: 0.6838\n",
      "Epoch 2/21\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.5065 - accuracy: 0.7534\n",
      "Epoch 3/21\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.4707 - accuracy: 0.7781\n",
      "Epoch 4/21\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.4550 - accuracy: 0.7858\n",
      "Epoch 5/21\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.4313 - accuracy: 0.8014\n",
      "Epoch 6/21\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.4163 - accuracy: 0.8106\n",
      "Epoch 7/21\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.4011 - accuracy: 0.8178\n",
      "Epoch 8/21\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.3930 - accuracy: 0.8232\n",
      "Epoch 9/21\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.3800 - accuracy: 0.8295\n",
      "Epoch 10/21\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.3737 - accuracy: 0.8330\n",
      "Epoch 11/21\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.3664 - accuracy: 0.8379\n",
      "Epoch 12/21\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.3591 - accuracy: 0.8419\n",
      "Epoch 13/21\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.3588 - accuracy: 0.8406\n",
      "Epoch 14/21\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.3499 - accuracy: 0.8473\n",
      "Epoch 15/21\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.3463 - accuracy: 0.8474\n",
      "Epoch 16/21\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.3419 - accuracy: 0.8509\n",
      "Epoch 17/21\n",
      "625/625 [==============================] - 17s 27ms/step - loss: 0.3375 - accuracy: 0.8534\n",
      "Epoch 18/21\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.3353 - accuracy: 0.8535\n",
      "Epoch 19/21\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.3289 - accuracy: 0.8568\n",
      "Epoch 20/21\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.3248 - accuracy: 0.8587\n",
      "Epoch 21/21\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.3191 - accuracy: 0.8616\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f13ec0e5370>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adam = Adam(learning_rate = 0.0001)\n",
    "adam = tf.keras.optimizers.Adam(learning_rate = 0.0001)\n",
    "\n",
    "m.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "m.fit(X_train_indices, Y_train,batch_size=64, epochs=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V54ngHmwXBk4",
    "outputId": "d1aea238-3257-4d44-9f88-bcff586feab8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-01 20:31:16.325908: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/my_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/my_model/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f13f29f9a60> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f13f289eb80> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f13f28a35b0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p saved_model\n",
    "m.save('saved_model/my_model') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hoPyOSV2XNRb",
    "outputId": "478601bc-db6b-4cb2-fe5c-1d408609a894"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 150)]             0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 150, 50)           5612100   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 150, 128)          91648     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 150, 128)          0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 150, 128)          131584    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 150, 128)          0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 128)               131584    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,967,045\n",
      "Trainable params: 354,945\n",
      "Non-trainable params: 5,612,100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model = tf.keras.models.load_model('saved_model/my_model')\n",
    "\n",
    "# Check its architecture\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d-WTE0KEXWYy",
    "outputId": "a08c4584-beff-4f15-e747-29c35551c837"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_model\n",
      "assets\tkeras_metadata.pb  saved_model.pb  variables\n"
     ]
    }
   ],
   "source": [
    "# my_model directory\n",
    "!ls saved_model\n",
    "\n",
    "# Contains an assets folder, saved_model.pb, and variables folder.\n",
    "!ls saved_model/my_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 5s 12ms/step - loss: 0.3507 - accuracy: 0.8441\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3506869375705719, 0.8440999984741211]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_indices = tokenizer.texts_to_sequences(X_test)\n",
    "X_test_indices = pad_sequences(X_test_indices, maxlen=maxLen, padding='post')\n",
    "m.evaluate(X_test_indices, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PW65YuwlXROm",
    "outputId": "5a36618e-9a65-48db-aa8f-d44c71eb2a9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 4s - loss: 0.3507 - accuracy: 0.8441 - 4s/epoch - 13ms/step\n",
      "Restored model, accuracy: 84.41%\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "loss, acc = new_model.evaluate(X_test_indices, Y_test, verbose=2)\n",
    "print('Restored model, accuracy: {:5.2f}%'.format(100 * acc))\n",
    "\n",
    "print(new_model.predict(X_test_indices).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UxfCqYy-TcTM",
    "outputId": "162934e2-85e8-479c-db51-0072a7930aa3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precicted sentiment : negative\n",
      "correct sentiment : negative\n"
     ]
    }
   ],
   "source": [
    "preds = m.predict(X_test_indices)\n",
    "\n",
    "n = np.random.randint(0,9999)\n",
    "\n",
    "X_test[n]\n",
    "\n",
    "if preds[n] > 0.5:\n",
    "  print('predicted sentiment : positive')\n",
    "else: \n",
    "  print('precicted sentiment : negative')\n",
    "\n",
    "if (Y_test[n] == 1):\n",
    "  print('correct sentiment : positive')\n",
    "else:\n",
    "  print('correct sentiment : negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "RWREqy37Tfch"
   },
   "outputs": [],
   "source": [
    "def add_score_predictions(data, reviews_list_idx):\n",
    "\n",
    "  data['sentiment score'] = 0\n",
    "\n",
    "  reviews_list_idx = pad_sequences(reviews_list_idx, maxlen=maxLen, padding='post')\n",
    "\n",
    "  review_preds = m.predict(reviews_list_idx)\n",
    "\n",
    "  data['sentiment score'] = review_preds\n",
    "\n",
    "  pred_sentiment = np.array(list(map(lambda x : 'positive' if x > 0.5 else 'negative',review_preds)))\n",
    "\n",
    "  data['predicted sentiment'] = 0\n",
    "\n",
    "  data['predicted sentiment'] = pred_sentiment\n",
    "\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "1fzt-mlzUi7Q"
   },
   "outputs": [],
   "source": [
    "a = []\n",
    "for i in range(0,50000):\n",
    "    a+=[[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "4elQ-7YzZNDi"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review without stopwords</th>\n",
       "      <th>clean_review</th>\n",
       "      <th>sentiment score</th>\n",
       "      <th>predicted sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>one reviewers mentioned watching just 1 oz epi...</td>\n",
       "      <td>one reviewers mentioned watching just 1 oz epi...</td>\n",
       "      <td>0.541370</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production. &lt;br /&gt;&lt;br /&gt;the...</td>\n",
       "      <td>positive</td>\n",
       "      <td>wonderful little production. &lt;br /&gt;&lt;br /&gt;the f...</td>\n",
       "      <td>wonderful little production  the filming techn...</td>\n",
       "      <td>0.492336</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>0.614129</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>basically family little boy (jake) thinks zomb...</td>\n",
       "      <td>basically family little boy  jake  thinks zomb...</td>\n",
       "      <td>0.529855</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>petter mattei's \"love time money\" visually stu...</td>\n",
       "      <td>petter mattei s  love time money  visually stu...</td>\n",
       "      <td>0.495821</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  \\\n",
       "0  one of the other reviewers has mentioned that ...  positive   \n",
       "1  a wonderful little production. <br /><br />the...  positive   \n",
       "2  i thought this was a wonderful way to spend ti...  positive   \n",
       "3  basically there's a family where a little boy ...  negative   \n",
       "4  petter mattei's \"love in the time of money\" is...  positive   \n",
       "\n",
       "                            review without stopwords  \\\n",
       "0  one reviewers mentioned watching just 1 oz epi...   \n",
       "1  wonderful little production. <br /><br />the f...   \n",
       "2  thought wonderful way spend time hot summer we...   \n",
       "3  basically family little boy (jake) thinks zomb...   \n",
       "4  petter mattei's \"love time money\" visually stu...   \n",
       "\n",
       "                                        clean_review  sentiment score  \\\n",
       "0  one reviewers mentioned watching just 1 oz epi...         0.541370   \n",
       "1  wonderful little production  the filming techn...         0.492336   \n",
       "2  thought wonderful way spend time hot summer we...         0.614129   \n",
       "3  basically family little boy  jake  thinks zomb...         0.529855   \n",
       "4  petter mattei s  love time money  visually stu...         0.495821   \n",
       "\n",
       "  predicted sentiment  \n",
       "0            positive  \n",
       "1            negative  \n",
       "2            positive  \n",
       "3            positive  \n",
       "4            negative  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = add_score_predictions(data,a)\n",
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 140
    },
    "id": "0Ey79TppYdJ2",
    "outputId": "0bda5dc4-7646-4553-b747-0a8264f88873"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a wonderful little production. <br /><br />the filming technique is very unassuming- very old-time-bbc fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />the actors are extremely well chosen- michael sheen not only \"has got all the polari\" but he has all the voices down pat too! you can truly see the seamless editing guided by the references to williams\\' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. a masterful production about one of the great master\\'s of comedy and his life. <br /><br />the realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional \\'dream\\' techniques remains solid then disappears. it plays on our knowledge and our senses, particularly with the scenes concerning orton and halliwell and the sets (particularly of their flat with halliwell\\'s murals decorating every surface) are terribly well done.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.review[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x4zTSP6dYhxT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "RNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
